{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claredavies/ImageIndexing/blob/master/Advanced_Techniques_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b4876a",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b361c569619c5777091368813c9298fb",
          "grade": false,
          "grade_id": "cell_head_1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "c1b4876a"
      },
      "source": [
        "# 11762 Content-Based Image Retrieval\n",
        "## Master's Degree in Intelligent Systems\n",
        "### University of the Balearic Islands\n",
        "\n",
        "---\n",
        "\n",
        "**Before you turn this problem in, please put your full names and DNIs (or NIEs) below, and execute the cell:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d2d1ee2d",
      "metadata": {
        "id": "d2d1ee2d"
      },
      "outputs": [],
      "source": [
        "NAME  = \"Clare Davies\"\n",
        "DNI   = \"PL5527043\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucTpN7Nu7ABm",
        "outputId": "d9c8ce3f-5112-4e54-9a81-54d70b23ab89"
      },
      "id": "ucTpN7Nu7ABm",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/ImageIndexing/iric_dev_kit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_AoMPrM7ApH",
        "outputId": "558c8a35-1985-4598-f948-cb95fe65451b"
      },
      "id": "q_AoMPrM7ApH",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ImageIndexing/iric_dev_kit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d05aa9e",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6e99971bb70936fbf488fd64ed0c1efa",
          "grade": false,
          "grade_id": "cell_head_2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6d05aa9e"
      },
      "source": [
        "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. **Justify** all of your answers, **graphically** wherever possible. Remember that this notebook will be considered as a report to the work done during the assignment.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "05c0ec04",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "20a5c47f6bb9d8cd5e66d23e3c5e7ef4",
          "grade": false,
          "grade_id": "cell-c3d4cadbc41f26fb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "05c0ec04"
      },
      "outputs": [],
      "source": [
        "# Setup code for this assignment\n",
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import scipy.cluster.vq as vq\n",
        "import tqdm\n",
        "import zipfile\n",
        "\n",
        "## Adding parent folder to find other libs\n",
        "import sys\n",
        "if \"..\" not in sys.path:\n",
        "    sys.path.insert(0,\"..\")\n",
        "    \n",
        "import iric_utils.eval_holidays as ev\n",
        "import iric_utils.read_descriptors as rd\n",
        "\n",
        "# Configuring Matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "089c7f13",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c5e211b475b088e5bbf4e9341e5c56ab",
          "grade": false,
          "grade_id": "cell-d55ea684dc7f6d83",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "089c7f13"
      },
      "source": [
        "## Introduction\n",
        "---\n",
        "The main goal of this assigment is to implement a complete CBIR system using VLAD, as image descriptor, in combination with Product Quantization (PQ), as indexing method. You will also experiment with a simple search reranking method.\n",
        "\n",
        "In this assigment, images will be described using the following steps:\n",
        "- Load a set of SIFT features for each image.\n",
        "- Aggregate these features into a VLAD vector.\n",
        "- (Optionally) Apply dimensionality reduction using PCA.\n",
        "\n",
        "Next, using the computed VLAD vectors, an index of images will be built by using PQ:\n",
        "- Build a set of quantizers (small vocabularies).\n",
        "- Encode database images using these quantizers.\n",
        "- Search query images in the index using the Asymmetric Distance Computation (ADC) approach to measure the system performance.\n",
        "\n",
        "As usual during this course, we will use the [INRIA Holidays](http://lear.inrialpes.fr/people/jegou/data.php) dataset. **Check previous assignments to further information about this dataset.**\n",
        "\n",
        "We also need the provided script to evaluate a CBIR system on this dataset. Remember that the performance is measured computing the **mean average precision** (mAP) over all queries. **Check also previous assignments to remember how to use this script and the different functions it offers.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d119c73f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "328a5d81a7c47d9e2ca31dd1f97b0ddc",
          "grade": false,
          "grade_id": "cell-404d56f0636d62ac",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d119c73f"
      },
      "source": [
        "### Loading images\n",
        "As we did in previous assignments, for managing images, we will create four lists:\n",
        "- **`query_names`**: File names of the *query* images\n",
        "- **`query_imgs`**: *Query* images loaded using OpenCV\n",
        "- **`train_names`**: File names of the *train* (database) images\n",
        "- **`train_imgs`**: *Train* images loaded using OpenCV\n",
        "\n",
        "In this assignment, we will use the original INRIA Holidays dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "efb60a66",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9c638a8490d3e44502d8f4faee4e8916",
          "grade": false,
          "grade_id": "cell-56d379a70cbf33d7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efb60a66",
        "outputId": "d5df49a7-03f0-44c8-d720-897e56370ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "991\n"
          ]
        }
      ],
      "source": [
        "# Separating the dataset into query and train images\n",
        "query_names = []\n",
        "query_imgs = []\n",
        "train_names = []\n",
        "train_imgs = []\n",
        "\n",
        "with open('../holidays/holidays_images.dat') as f:\n",
        "    for line in f:\n",
        "        imname = line.strip()\n",
        "        imno = int(imname[:-len(\".jpg\")])\n",
        "        img = cv2.imread('../holidays/images/' + imname)\n",
        "        # Resize the images for a faster operation in this assignment\n",
        "        img = cv2.resize(img, None, fx=0.25, fy=0.25, interpolation = cv2.INTER_CUBIC)\n",
        "    \n",
        "        # Checking if this is a query image\n",
        "        if imno % 100 == 0:\n",
        "            query_names.append(imname)\n",
        "            query_imgs.append(img)\n",
        "        else:\n",
        "            train_names.append(imname)\n",
        "            train_imgs.append(img)\n",
        "\n",
        "print(len(query_names))\n",
        "print(len(train_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7c7c152",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ef0bee1eeb76015511fba82bafff8f0e",
          "grade": false,
          "grade_id": "cell-72ea50ea05235cc5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "c7c7c152"
      },
      "source": [
        "## Loading SIFT descriptors\n",
        "In this assignment we will create four additional lists:\n",
        "- **`query_kps`**: A list of lists of keypoints (cv2.KeyPoint) extracted from the *query* images\n",
        "- **`query_desc`**: A list of numpy arrays including, for each set of keypoints, the SIFT descriptors extracted from the *query* images\n",
        "- **`train_kps`**: A list of lists of keypoints (cv2.KeyPoint) extracted from the *train* (database) images\n",
        "- **`train_desc`**: A list of numpy arrays including, for each set of keypoints, the SIFT descriptors extracted from the *train* images\n",
        "\n",
        "As we did in Assigment 2, you are provided with a set of SIFT descriptors for each image, and, therefore, you do not need to create these lists from scratch. If you do no have these descriptors in your computer, first, download them from [here](https://uibes-my.sharepoint.com/:u:/g/personal/egf350_id_uib_es/Eam8Ld8YDaJAhNr91YVdAZIB_wVZJ8kzzKD7BR6R3LziMw).\n",
        "\n",
        "> **Unzip this file into the root directory of the development kit, at the same level of the datasets.**\n",
        "\n",
        "Remember that these descriptors are in a directory called `siftgeo` that should be in your workspace, containing the set of SIFT descriptors for each image of the dataset. These descriptors are stored in binary format and, thus, you are also provided with some tools to load them. To be more precise, you can call the function `load_SIFT_descriptors` to load the descriptors of a list of images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "403e0d0b",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7c25a280008771e9cab1f70cea889489",
          "grade": false,
          "grade_id": "cell-7ae7555b1b4ef435",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "403e0d0b",
        "outputId": "9795673a-b2c2-4ef1-f060-89ca2eac3462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "991\n",
            "500\n",
            "991\n",
            "(1000, 128)\n",
            "[[10.  6. 52. ... 15.  4.  0.]\n",
            " [16. 50. 12. ... 15.  4.  0.]\n",
            " [10. 11. 58. ...  7.  4.  4.]\n",
            " ...\n",
            " [27. 15.  0. ... 16.  8. 12.]\n",
            " [51. 47. 14. ... 35. 26.  0.]\n",
            " [ 2. 37. 25. ... 47. 13.  8.]]\n"
          ]
        }
      ],
      "source": [
        "# Loading descriptors\n",
        "query_kps, query_desc = rd.load_SIFT_descriptors(query_names, max_desc=1000)\n",
        "train_kps, train_desc = rd.load_SIFT_descriptors(train_names, max_desc=1000)\n",
        "\n",
        "# Some prints\n",
        "print(len(query_kps))\n",
        "print(len(train_kps))\n",
        "print(len(query_desc))\n",
        "print(len(train_desc))\n",
        "print(query_desc[0].shape)\n",
        "print(query_desc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df66ea08",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5f3d9bf3742ba758e024519279fb77a0",
          "grade": false,
          "grade_id": "cell-40b24f326ba0393a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "df66ea08"
      },
      "source": [
        "For development purposes, we use the parameter `max_desc` to load a maximum number (1000) of the descriptors. This will speed up the execution of the rest of the notebook, while the decrease in performance will be minimum.\n",
        "\n",
        "> **Some images do not have keypoints/descriptors. Take this into account when you develop your solution.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c5142c1",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1e1667ffc981315c5e820ab5e12662a6",
          "grade": false,
          "grade_id": "cell-ced3194580cf26a7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2c5142c1"
      },
      "source": [
        "## VLAD\n",
        "---\n",
        "Next step is to generate a VLAD vector for each image, aggregating its SIFT descriptors according to a visual vocabulary. You are provided with several small pretrained vocabularies to this end. Now, to develop the assignment, let's load one of these vocabularies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f6164f78",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1bad411012229bb3f7f11beef5edab0a",
          "grade": false,
          "grade_id": "cell-56b63f7574abcfe1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6164f78",
        "outputId": "676b7471-fcc2-4a33-af0e-691098e85a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 128)\n"
          ]
        }
      ],
      "source": [
        "# Loading a vocabulary files to be used in the VLAD approach.\n",
        "vocab = np.load('vocabs/sift_32c.npy')\n",
        "print(vocab.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e75c4a4",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5078fdc20927f67b759ec36ef1503e28",
          "grade": false,
          "grade_id": "cell-1eb0db1df8c37523",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4e75c4a4"
      },
      "source": [
        "Now it is your turn. Write a function called `compute_vlad` to compute the VLAD representation of an image. Additionally, perform a L2 normalization of the VLAD vector $V$:\n",
        "$$\n",
        "v_i = \\frac{v_i}{\\left\\lVert V\\right\\rVert_2}\n",
        "$$\n",
        "which means dividing each component $v_i$ by the L2 norm of $V$:\n",
        "\n",
        "> **Useful functions**: [numpy.linalg.norm](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html), [scipy.cluster.vq.vq](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.vq.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8a4d87c9",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1506255c0723c378dc2de3e3f4e3f223",
          "grade": false,
          "grade_id": "cell-d414bd746061eca0",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "8a4d87c9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.cluster.vq import vq\n",
        "\n",
        "#  Write a function called compute_vlad to compute the VLAD representation of an image. Additionally, perform a L2 normalization of the VLAD vector  𝑉\n",
        "# Useful functions: numpy.linalg.norm, scipy.cluster.vq.vq\n",
        "def compute_vlad(descs, vocab):\n",
        "    '''\n",
        "    Compute VLAD representation of an image.\n",
        "    \n",
        "    - descs: A numpy array. It is the set descriptors extracted from the image.\n",
        "        e.g. using SIFT, the size will be (N, 128), being N the number of features.\n",
        "    - vocab: A numpy array representing the vocabulary.\n",
        "        Using SIFT, the size will be (k, 128), where k is the number of visual\n",
        "        words of the vocabulary.\n",
        "  \n",
        "    RETURN: \n",
        "    - VLAD l2-normalized vector of the image, represented as a numpy vector. \n",
        "        The size will be, using SIFT, (k * 128, ), being k the number of visual \n",
        "        words of 'vocab'.\n",
        "    '''  \n",
        "    # Step 1: Assign descriptors to visual words\n",
        "    codes, _ = vq(descs, vocab)\n",
        "\n",
        "    # Step 2: Compute residuals for each visual word\n",
        "    residuals = np.zeros_like(vocab)\n",
        "    for i in range(vocab.shape[0]):\n",
        "        mask = codes == i\n",
        "        residuals[i] = np.sum(descs[mask] - vocab[i], axis=0)\n",
        "\n",
        "    # Step 3: Create the VLAD vector by concatenating residuals\n",
        "    vlad = residuals.flatten()\n",
        "\n",
        "    # Step 4: Perform L2 normalization\n",
        "    vlad = vlad / np.linalg.norm(vlad)\n",
        "\n",
        "    return vlad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a9f1c83c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4703d184ec9181ec938257221b35b0ef",
          "grade": true,
          "grade_id": "cell-ac86c9135d6313ba",
          "locked": true,
          "points": 0.4,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9f1c83c",
        "outputId": "870b9633-af03-4b41-edf7-503a2d22c4c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.01708985 -0.00229319  0.00131438 ... -0.00762179 -0.0083055\n",
            "  0.01966916]\n"
          ]
        }
      ],
      "source": [
        "vlad_desc = compute_vlad(query_desc[0], vocab)\n",
        "print(vlad_desc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48d913e1",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "228ab7eb5348444029947c1445296ab2",
          "grade": false,
          "grade_id": "cell-fd14629de5a27675",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "48d913e1"
      },
      "source": [
        "Now write a function called `describe_images_VLAD` to compute VLAD descriptors of a list of images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a3df7234",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "16316b7a450896d0fb6201add034a5f4",
          "grade": false,
          "grade_id": "cell-cca16107c0706b5b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "a3df7234"
      },
      "outputs": [],
      "source": [
        "def describe_images_VLAD(imgs_desc, vocab):  \n",
        "    '''\n",
        "    Compute the VLAD representation of a list of images.\n",
        "    \n",
        "    - img_descs: A list containing numpy arrays of size (N, 128), using SIFT and\n",
        "        being N the number of features. Each numpy array i corresponds to the \n",
        "        descriptors found at image i.\n",
        "    - vocab: A numpy array representing the vocabulary.\n",
        "        Using SIFT, the size will be (k, 128), where k is the number of visual\n",
        "        words of the vocabulary.\n",
        "  \n",
        "    RETURN: \n",
        "    - A list where each item i is the l2-norm VLAD vector of image img_descs[i].\n",
        "    ''' \n",
        "  \n",
        "    imgs_vlad = []\n",
        "\n",
        "    for img_desc in imgs_desc:\n",
        "        # get the VLAD representation of the image\n",
        "        code, _ = vq(img_desc, vocab)\n",
        "        vlad = np.zeros((vocab.shape[0], vocab.shape[1]))\n",
        "\n",
        "        # accumulate the residuals\n",
        "        for i in range(vocab.shape[0]):\n",
        "            if np.sum(code == i) > 0:\n",
        "                residuals = img_desc[code == i] - vocab[i]\n",
        "                vlad[i] = residuals.sum(axis=0)\n",
        "\n",
        "        # l2-normalize the VLAD vector\n",
        "        vlad = vlad.flatten()\n",
        "        norm = np.linalg.norm(vlad)\n",
        "        if norm != 0:\n",
        "            vlad /= norm\n",
        "\n",
        "        # convert the VLAD vector to a common data type (float)\n",
        "        vlad = vlad.astype(float)\n",
        "\n",
        "        imgs_vlad.append(vlad)\n",
        "\n",
        "    return imgs_vlad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f9756041",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b5a3f318087fffde21568855e4f06668",
          "grade": true,
          "grade_id": "cell-5a06cecfe05fbd40",
          "locked": true,
          "points": 0.15,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9756041",
        "outputId": "45ed1f57-a27e-4cb3-a58d-c24b113c3b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "991\n",
            "500\n",
            "(4096,)\n",
            "(4096,)\n",
            "[-0.0166616   0.01173472  0.00454088 ...  0.00689059  0.00051252\n",
            "  0.00820919]\n",
            "[-0.01708985 -0.00229319  0.00131438 ... -0.00762179 -0.00830551\n",
            "  0.01966916]\n"
          ]
        }
      ],
      "source": [
        "query_vlad = describe_images_VLAD(query_desc, vocab)\n",
        "train_vlad = describe_images_VLAD(train_desc, vocab)\n",
        "print(len(train_vlad))\n",
        "print(len(query_vlad))\n",
        "print(train_vlad[0].shape)\n",
        "print(query_vlad[0].shape)\n",
        "print(train_vlad[0])\n",
        "print(query_vlad[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7186287",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ad44faa034da29155ef380f5766fcf15",
          "grade": false,
          "grade_id": "cell-d8e35daf18fb336a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "f7186287"
      },
      "source": [
        "## Product Quantization\n",
        "---\n",
        "In this section you'll build a set of functions to implement Product Quantization (PQ) for indexing VLAD descriptors. In PQ, each vector $x$ of size $D$ is split into $m$ distinct subvectors of dimension $D^∗ = D / m$, where $D$ is a multiple of $m$. Subvectors are quantized separately using $m$ distinct quantizers (small vocabularies) each one with $k$ centroids (visual words).\n",
        "\n",
        "**Example**: \n",
        "- Using SIFT descriptors (128 dimensions) and a vocabulary with 32 visual words, the final VLAD vector will have 128 $\\times$ 32 = 4096 dimensions without applying any dimensionality reduction method.\n",
        "- We can split these vectors into 8 parts ($m$ = 8) corresponding each part to a subvector of $D / m = 4096 / 8 = 512$ components.\n",
        "- Given a training set of descriptors, a quantizer can be learnt for each of these parts using, for instance, 256 centroids ($k$ = 256), which can be encoded using 8 bits per quantizer.\n",
        "- The dimensions of each of the $m$ quantizers will then be (256, 512).\n",
        "- As a result of this process, a VLAD vector of 4096 dimensions can be encoded using 8 integers, where each integer is encoded using 8 bits (0, ..., 255), corresponding to the index of the closest centroid on this quantizer.\n",
        "\n",
        "First step is to train a set of quantizers from some given VLAD vectors. Write a function called `pq_build_quantizers` to this end:\n",
        "\n",
        "> **Useful functions**: [scipy.cluster.vq.kmeans2](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.kmeans2.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "07525388",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3484c9411f95772a62c9adeede08c370",
          "grade": false,
          "grade_id": "cell-c9d19caaabd57de4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "07525388"
      },
      "outputs": [],
      "source": [
        "# First step is to train a set of quantizers from some given VLAD vectors. Write a function called pq_build_quantizers to this end:\n",
        "from scipy.cluster.vq import kmeans2\n",
        "# Useful functions: scipy.cluster.vq.kmeans2\n",
        "def pq_build_quantizers(descs, m = 8, k = 256):\n",
        "    '''\n",
        "    Create a list of m quantizers with k centroids each one.\n",
        "    \n",
        "    - descs: A list containing VLAD vectors of size (D, ).\n",
        "        Each element i is a numpy array extracted from the set of descriptors \n",
        "        of image i.\n",
        "    - m: Number of quantizers to train. Each quantizer will be trained using\n",
        "        vectors of length D / m.\n",
        "    - k: Number of centroids (visual words) to compute for each of the m quantizers.\n",
        "  \n",
        "    RETURN: \n",
        "    - A list of m quantizers. Each quantizer is a numpy array of size (k, D / m) \n",
        "        containing the centroids obtained after a clustering procedure.\n",
        "    '''\n",
        "  \n",
        "    quantizers = [] # List of vocabularies\n",
        "    D = descs[0].shape[0]\n",
        "    d = D // m # Dimension of each subvector\n",
        "    \n",
        "    for i in range(m):\n",
        "        subvecs = np.zeros((len(descs), d))\n",
        "        for j, desc in enumerate(descs):\n",
        "            subvecs[j] = desc[i*d:(i+1)*d]\n",
        "        centroids, _ = kmeans2(subvecs, k, minit='random')\n",
        "        quantizers.append(centroids)\n",
        "        \n",
        "    return quantizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e8e775dd",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0f940360a6f2f35f4876c1c8581d0191",
          "grade": true,
          "grade_id": "cell-d761f1f74df549fa",
          "locked": true,
          "points": 0.2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8e775dd",
        "outputId": "0b507054-a367-4298-cc4f-9c914f078ba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "(256, 512)\n",
            "(256, 512)\n",
            "(256, 512)\n",
            "(256, 512)\n",
            "(256, 512)\n",
            "(256, 512)\n",
            "(256, 512)\n",
            "(256, 512)\n"
          ]
        }
      ],
      "source": [
        "# Check the previous function with the following code\n",
        "quantizers = pq_build_quantizers(train_vlad, m = 8, k = 256)\n",
        "print(len(quantizers))\n",
        "for q in quantizers:\n",
        "    print(q.shape)    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96571964",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "530cc5c6fe34e2a0026158d9044c90ad",
          "grade": false,
          "grade_id": "cell-505fb462b578309e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "96571964"
      },
      "source": [
        "Now write a function to encode a VLAD vector using a set of quantizers:\n",
        "\n",
        "> **Useful functions**: [scipy.cluster.vq.vq](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.vq.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67e099be",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7153f9049c60e3f732f1835f80f71796",
          "grade": false,
          "grade_id": "cell-b8a26eb701b53745",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "67e099be"
      },
      "outputs": [],
      "source": [
        "def pq_encode_vector(v, quantizers):\n",
        "    '''\n",
        "    Encode a VLAD vector v using a set of pre-trained set of quantizers.\n",
        "    \n",
        "    - v: VLAD vector to encode, represented as a numpy array of size (D, ).  \n",
        "    - quantizers: A list of m quantizers. \n",
        "        Each one is a numpy array of size (k, D / m), where k and m where\n",
        "        defined during the vocabulary construction.\n",
        "  \n",
        "    RETURN: \n",
        "    - VLAD vector encoded using m values.\n",
        "    '''\n",
        "  \n",
        "    # Inferring m from 'quantizers'\n",
        "    m = len(quantizers)\n",
        "    code = np.zeros((m, 1))\n",
        "  \n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "      \n",
        "    return code.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58e87552",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "277d7300066b120f4925e99b871a8efe",
          "grade": true,
          "grade_id": "cell-df898c917eba295e",
          "locked": true,
          "points": 0.3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "58e87552"
      },
      "outputs": [],
      "source": [
        "code = pq_encode_vector(train_vlad[2], quantizers)\n",
        "print(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c039d7",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "652b218ea35a8f34e6df98a488efb776",
          "grade": false,
          "grade_id": "cell-63637ed9196118c4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "e7c039d7"
      },
      "source": [
        "Now it's time to write a function for building an index of images using PQ. This function must encode each VLAD descriptor of the images that we want to index using a set of pre-trained quantizers. The function must return these codes as a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eabbde27",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f41219464129749fc7d59b92efd8aee4",
          "grade": false,
          "grade_id": "cell-5ba2dfdfe377ee1e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "eabbde27"
      },
      "outputs": [],
      "source": [
        "def pq_build_index(descs, quantizers):\n",
        "    '''\n",
        "    Build a PQ index from a set of descriptors and quantizers.\n",
        "    \n",
        "    - descs: A list containing VLAD vectors of size (D, ) that we want to index.\n",
        "        Each element i is a numpy array extracted from the image i.\n",
        "    - quantizers: A list of m quantizers.\n",
        "        Each one is a numpy array of size (k, D / m), where k and m where\n",
        "        defined during the vocabulary construction.\n",
        "  \n",
        "    RETURN:\n",
        "    - A list where each element i is the encoded version of descs[i] using the\n",
        "        quantizers to compute the code.\n",
        "    '''\n",
        "      \n",
        "    index = []\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "      \n",
        "    return index  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3526d21c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ef486798c4393c10037fd997a9558685",
          "grade": true,
          "grade_id": "cell-6fa7a4d6dc563b65",
          "locked": true,
          "points": 0.15,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3526d21c"
      },
      "outputs": [],
      "source": [
        "# Check your implementation\n",
        "index = pq_build_index(train_vlad[0:2], quantizers)\n",
        "print(len(index))\n",
        "print(len(index[0]))\n",
        "print(index[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0422d74f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e462c68836c5536ed6c57e8001b92b83",
          "grade": false,
          "grade_id": "cell-d228da8ef6b74ed2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0422d74f"
      },
      "source": [
        "Once we have encoded a set of VLAD vectors to create our PQ index, it is time to search images on it. This requires to write a function to compute the L2 distance between a query vector $x$ and a database vector $y$. In this assignment, you'll implement the *Asymmetric Distance Computation* (ADC) method, where the database vector $y$ is represented by its encoded version but the query $x$ is not encoded (raw VLAD vector). The distance is then approximated as:\n",
        "\n",
        "$$\n",
        "d(x, y)^2 \\approx \\sum_{i=1}^{m} d(x_i, q_i(y_i))^2\n",
        "$$\n",
        "\n",
        "Note that $q_i(y_i)$ for a vector $y$ is what we have stored in our index. Now write a function called `pq_distance` to compute this approximation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c450607",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d4e9fc135490e28f1121910bd20f1277",
          "grade": false,
          "grade_id": "cell-85787c85e17adb75",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "2c450607"
      },
      "outputs": [],
      "source": [
        "def pq_distance(x, y, quantizers):\n",
        "    '''\n",
        "    Compute an approximated L2 distance between x and y using the ADC method.\n",
        "    \n",
        "    - x: Query VLAD vector represented as a numpy array of size (D, ).\n",
        "    - y: Database vector encoded using PQ with length = m.\n",
        "    - quantizers: A list of m quantizers.\n",
        "        Each one is a numpy array of size (k, D / m), where k and m where\n",
        "        defined during the vocabulary construction.\n",
        "  \n",
        "    RETURNS:\n",
        "    - Approximated L2 distance between x and y\n",
        "    '''\n",
        "  \n",
        "    dist = 0.0\n",
        "  \n",
        "    # Number of quantizers\n",
        "    m = len(quantizers)    \n",
        "    \n",
        "    # Centrois for each quantizer\n",
        "    k = quantizers[0].shape[0]\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "  \n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03b00f5f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "16b7f31d04b05831606b777688db0c9b",
          "grade": true,
          "grade_id": "cell-f4447e1bda362c1e",
          "locked": true,
          "points": 0.3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "03b00f5f"
      },
      "outputs": [],
      "source": [
        "# Computing the VLAD description of a query image.\n",
        "print('Query image: ', query_names[0])\n",
        "\n",
        "# Computing L2 distance to the first 20 images.\n",
        "print('Distances:')\n",
        "for i in range(20):\n",
        "    train = pq_encode_vector(train_vlad[i], quantizers)\n",
        "    d = pq_distance(query_vlad[0], train, quantizers)\n",
        "    print(train_names[i], str(d))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fd6e7b5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5a6793f2b548295a211d960be07eb182",
          "grade": false,
          "grade_id": "cell-64306d0dd7663807",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0fd6e7b5"
      },
      "source": [
        "Next, as in other assignmnets, write a function called `search_image` to search a query image in the index:\n",
        "- You have to implement the standard PQ method which computes *sequentially* the L2 distance between the query vector $x$ and all database vectors $y$  and then results are sorted according to their distances.\n",
        "- Remember that to speed up the search process, you can precompute all distances between query subvectors and centroids $d(x_i, c_{i, j})^2$ and stored them in look-up tables, computed for each query descriptor $x$. You are not required to implement this functionality given the small size of our image database, but feel free to implement it if you want and adapt the PQ functions for these purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f0c48e7",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "23cc808d80cfd282602f25953bcbf935",
          "grade": false,
          "grade_id": "cell-caa776c2069c5a2c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "7f0c48e7"
      },
      "outputs": [],
      "source": [
        "def search_image(desc, index, quantizers, img_names):\n",
        "    '''\n",
        "    Search an image in the index\n",
        "    \n",
        "    - descs: Query VLAD vector represented as a numpy array of size (D, ).\n",
        "    - index: A list where each element i is the encoded version of an image of the database.\n",
        "    - quantizers: A list of m quantizers.\n",
        "        Each one is a numpy array of size (k, D / m), where k and m where\n",
        "        defined during the vocabulary construction.\n",
        "    - img_names: A list of image names to associate each code in 'index' with \n",
        "        its string name in the dataset.\n",
        "  \n",
        "    RETURN:\n",
        "      - An ordered list of similar images, e.g.: ['100101.jpg', '100202.jpg', ...]\n",
        "    '''\n",
        "    \n",
        "    # Number of quantizers\n",
        "    m = len(quantizers)    \n",
        "    \n",
        "    # Centrois for each quantizer\n",
        "    k = quantizers[0].shape[0]\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ed3682f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c7a7c6d481bd4d937b597a81615d8546",
          "grade": true,
          "grade_id": "cell-7e98cb52848742ee",
          "locked": true,
          "points": 0.25,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1ed3682f"
      },
      "outputs": [],
      "source": [
        "# Search an image in the index\n",
        "img_res = search_image(query_vlad[0], index, quantizers, train_names[0:2])\n",
        "print(img_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a002f86",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "980c137a75c121919a6bf469c3ee1a43",
          "grade": false,
          "grade_id": "cell-d54a7ad8b26b9409",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1a002f86"
      },
      "source": [
        "Finally, as usual, write a function called `compute_mAP` to compute the performance of the system, given a list of query images. This function should return a Python dictionary with the ordered results for each query along with the computed mAP:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eb648dd",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "65e99676e1e982ab521f55e355bf9e39",
          "grade": false,
          "grade_id": "cell-691078192e4858d6",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "6eb648dd"
      },
      "outputs": [],
      "source": [
        "def compute_mAP(query_names, query_descs, index, train_names, quantizers):\n",
        "    '''\n",
        "    Perform a search for a list of query images against the database.\n",
        "    \n",
        "    - query_names: An ordered list with the names of query images.\n",
        "    - query_descs: A list containing VLAD vectors of size (D, ) we want to search.\n",
        "        Each element i is a numpy array extracted from the image i.\n",
        "    - index: Index of images to search query descriptors.\n",
        "    - train_names: A list of image names to associate each code in 'index' with \n",
        "        its name in the dataset.    \n",
        "    - quantizers: A list of m quantizers.\n",
        "        Each one is a numpy array of size (k, D / m), where k and m where\n",
        "        defined during the vocabulary construction.\n",
        "  \n",
        "    RETURN:\n",
        "    - total_results: A dictionary containing, for each query image,\n",
        "        an ordered list of the retrieved images.\n",
        "    - m_ap: Mean Average Precision averaged over all queries.\n",
        "    '''\n",
        "    total_results = {}\n",
        "    m_ap = 0.0  \n",
        "    \n",
        "    # Number of quantizers\n",
        "    m = len(quantizers)    \n",
        "    \n",
        "    # Centrois for each quantizer\n",
        "    k = quantizers[0].shape[0]\n",
        "  \n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "    \n",
        "    return total_results, m_ap  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b33ef09",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a18349071c795ecffbc8401689be11c2",
          "grade": true,
          "grade_id": "cell-33af834e8f213922",
          "locked": true,
          "points": 0.15,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "5b33ef09"
      },
      "outputs": [],
      "source": [
        "# Example of computing mAP\n",
        "results, mAP = compute_mAP(query_names, query_vlad, index, train_names[0:2], quantizers)\n",
        "print(results['100000.jpg'])\n",
        "print(results['100100.jpg'])\n",
        "print(mAP) # This should be close to 0 now, since there is only two images in the database."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9faaadc",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3bfdc23166645dba75eada4dde824930",
          "grade": false,
          "grade_id": "cell-307ceb07e3b7ecdf",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "b9faaadc"
      },
      "source": [
        "**Q1**: In the following cell compute the resulting mAP of the system **for each of the three vocabularies provided (16c, 32c, 64c),** using $m$ = 8 and $k$ = 256. Train the quantizers using VLAD descriptors of the train images. Note that an independent and larger dataset here will be better, but for simplicity, we use the same images we want to index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "604f78dd",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "21d8fc82c59355ed16c03ee068577e11",
          "grade": false,
          "grade_id": "cell-85a7e3a3a8e6a73d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "604f78dd"
      },
      "outputs": [],
      "source": [
        "# Fill these variables with the resulting mAP\n",
        "mAP_16c  = 0.0\n",
        "mAP_32c  = 0.0\n",
        "mAP_64c  = 0.0\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eceab37",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "dcdf97a1ef1d47299181c23bb0f4ab59",
          "grade": true,
          "grade_id": "cell-70e62b6812f4f3b4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0eceab37"
      },
      "outputs": [],
      "source": [
        "print('mAP 16c: %.5f' % mAP_16c)\n",
        "print('mAP 32c: %.5f' % mAP_32c)\n",
        "print('mAP 64c: %.5f' % mAP_64c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92d502d6",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5a767f4db5eeda93007fdd7d05f82b75",
          "grade": false,
          "grade_id": "cell-0f3403464b36441c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "92d502d6"
      },
      "source": [
        "**Q2**: Compare the performances obtained on each case. Is a larger vocabulary size always better? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ef2c22a",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b14bee47354fc5eeb4d8956df246f42c",
          "grade": false,
          "grade_id": "cell-d810cafd17e8be3c",
          "locked": true,
          "points": 0.75,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "6ef2c22a"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d740ef5f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f2abcbba2c734ac68474b1a9d07135dd",
          "grade": false,
          "grade_id": "cell-32d94270b9a99f2c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d740ef5f"
      },
      "source": [
        "**Q3**: Using the vocabulary which achieves the best performance in the previous point, analyze the effects of changing the parameters $m$ and $k$ in terms of mAP (always use multiples of 8). Some plots here can be useful to justify your answer. What about times (training and testing)? Do they vary?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88e63187",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "08843a567938c1d6852147e2506bce79",
          "grade": false,
          "grade_id": "cell-396f1cf0f08478bc",
          "locked": true,
          "points": 1.5,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "88e63187"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "110989f3",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "914e7ce38c68df2f1d42b96a3161f356",
          "grade": false,
          "grade_id": "cell-e1815efcc59b5e7e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "110989f3"
      },
      "source": [
        "## Search Reranking\n",
        "---\n",
        "As a final step, you will play with a *Relevance Feedback* method. More precisely, you will write the required code to implement the **Ide Dec-Hi** algorithm. Remember that it is a simple variant of the Rocchio algorithm where only one non-relevant result is employed.\n",
        "\n",
        "First, to implement this method, we need a way to classify an initial set of results in *relevant* and *non-relevant* for a given query. As we saw, in computer vision, this is typically carried out using geometric spatial verificacion techniques. However, in this assignment, for simplicity and to speed up the execution, we will make use of the following function that separates a list of results in *relevant* and *non-relevant* using just the name of the images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c40a0328",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bd323431de43518d74858858ac45e6f4",
          "grade": false,
          "grade_id": "cell-754b3925da92dc84",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "c40a0328"
      },
      "outputs": [],
      "source": [
        "def validate_results(query_name, list_of_results):\n",
        "    '''\n",
        "    Separate a result list into relevant and non-relevant results.\n",
        "    \n",
        "    - query_name: Name of the query image.\n",
        "    - list_of_results: An ordered list of similar images following the format\n",
        "        returned by the 'search_image' function.\n",
        "  \n",
        "    RETURN:\n",
        "    - relevant: An ordered list of relevant images in list_of_results.\n",
        "    - non-relevant: An ordered list of non-relevant images in list_of_results.\n",
        "    '''\n",
        "  \n",
        "    relevant = []\n",
        "    non_relevant = []\n",
        "      \n",
        "    q_imno = int(query_name[:-len(\".jpg\")])\n",
        "  \n",
        "    for res in list_of_results:\n",
        "        t_imno = int(res[:-len(\".jpg\")])\n",
        "        if np.abs(t_imno - q_imno) < 10:\n",
        "            relevant.append(res)\n",
        "        else:\n",
        "            non_relevant.append(res)\n",
        "  \n",
        "    return relevant, non_relevant"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1f715f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0630a72f4bdda22ed4f2ed7d2a37870b",
          "grade": false,
          "grade_id": "cell-73fc09912978f2d8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3e1f715f"
      },
      "source": [
        "Check the function using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92157907",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "862332f43a8c0a89a45aeec0373034be",
          "grade": false,
          "grade_id": "cell-a534a0b74909bd53",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "92157907"
      },
      "outputs": [],
      "source": [
        "# Describe images using VLAD\n",
        "query_vlad = describe_images_VLAD(query_desc, vocab_32c)\n",
        "train_vlad = describe_images_VLAD(train_desc, vocab_32c)\n",
        "\n",
        "# Train quantizers\n",
        "quants = pq_build_quantizers(train_vlad, m = 8, k = 256)\n",
        "\n",
        "# Create an index\n",
        "index = pq_build_index(train_vlad, quants)\n",
        "\n",
        "i = 5\n",
        "print(query_names[i])\n",
        "r = search_image(query_vlad[i], index, quants, train_names)\n",
        "print(r)\n",
        "rev, nrev = validate_results(query_names[i], r)\n",
        "print(rev)\n",
        "print(nrev[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f57ce5b4",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3505234b9ba0fd528dd5145bea56e3d2",
          "grade": false,
          "grade_id": "cell-5bd88f530e26457b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "f57ce5b4"
      },
      "source": [
        "Write a function called `compute_mAP_rf`. This function will do mainly the same as `compute_mAP`, but adding the Ide Dec-Hi algorithm as a *Relevance Feedback* method to enhance the retrieval results. For each query image:\n",
        "- Perform an initial query using the original VLAD descriptor $Q_0$.\n",
        "- Validate the obtained results, classifying images into *relevant* or *non-relevant*.\n",
        "- If there is at least 1 *relevant* result, compute a new query vector as:\n",
        "$$\n",
        "Q_m = \\alpha Q_0 + \\beta \\frac{1}{|D_r|} \\displaystyle \\sum_{i=1}^{|D_r|} D_r^i - \\gamma D_{nr}^0\\,,\n",
        "$$\n",
        "where $\\alpha$, $\\beta$ and $\\gamma$ are the weights used in the algorithm, $D_r$ is the set of *relevant* images and $D_{nr}^0$ is the best *non-relevant* image (just one). Otherwise, the search is over.\n",
        "- Re-query **once** using $Q_m$. This will be the final result set for this query image. You can also append the results to the original set.\n",
        "\n",
        "Notice that we will use VLAD vectors to compute $Q_m$ and, therefore, we will need the original set (*train_descs*), since the index contains the encoded version of the database images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b739e1",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "00011b88f9917e488d30e76d2ac878d9",
          "grade": false,
          "grade_id": "cell-15a53009d74717f7",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "56b739e1"
      },
      "outputs": [],
      "source": [
        "def compute_mAP_rf(query_names, query_descs, train_names, train_descs, index, \n",
        "              quantizers, alpha = 1.0, beta = 0.75, gamma = 0.25):  \n",
        "    '''\n",
        "    Perform a search for a list of query images against the database, adding Ide\n",
        "     Dec-Hi as a RF method.\n",
        "    \n",
        "    - query_names: An ordered list with the names of query images.\n",
        "    - query_descs: A list containing VLAD vectors of size (D, ) we want to search.\n",
        "        Each element i is a numpy array extracted from the image i.\n",
        "    - train_names: A list of image names to associate each code in 'index' with \n",
        "        its name in the dataset.\n",
        "    - train_descs: A list containing VLAD vectors of size (D, ) corresponding to \n",
        "        the database images.\n",
        "    - index: Index of images to search the query descriptors.\n",
        "    - quantizers: A list of m quantizers.\n",
        "        Each one is a numpy array of size (k, D / m), where k and m where\n",
        "        defined during the vocabulary construction.\n",
        "    - alpha, beta, gamma: Ide's Dec-Hi algorithm weights.\n",
        "  \n",
        "    RETURN: \n",
        "    - total_results: A dictionary containing, for each query image, \n",
        "        an ordered list of the retrieved images.\n",
        "    - m_ap: Mean Average Precision averaged over all queries.\n",
        "    '''\n",
        "    \n",
        "    total_results = {}\n",
        "    m_ap = 0.0\n",
        "    \n",
        "    # Number of quantizers\n",
        "    m = len(quantizers)    \n",
        "    \n",
        "    # Centrois for each quantizer\n",
        "    k = quantizers[0].shape[0]\n",
        "  \n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "  \n",
        "    return total_results, m_ap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9fe5d19",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "55f2e44a2bc3a0b717cba436fed08261",
          "grade": true,
          "grade_id": "cell-4c6e72449fcf1a1c",
          "locked": true,
          "points": 0.6,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "e9fe5d19"
      },
      "outputs": [],
      "source": [
        "# Example of computing mAP\n",
        "results, mAP = compute_mAP_rf(query_names, query_vlad, train_names[0:2], train_desc[0:2], index, quantizers)\n",
        "print(results['100000.jpg'])\n",
        "print(results['100100.jpg'])\n",
        "print(mAP) # This should be close to 0 now, since there is only two images in the database."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "928245af",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4411ba81a33b5eb8dca13780f0888c04",
          "grade": false,
          "grade_id": "cell-8ddc18112d33a31c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "928245af"
      },
      "source": [
        "**Q4**: Compute the mAP obtained using this function (`compute_mAP_rf`) for different vocabularies and values of $m$ and $k$. Verify if there exists an increment of performance with regard to the same configuration without using de Dec-Hi algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cf8e351",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3d648f5dc07f308d2d13c3944185e99d",
          "grade": false,
          "grade_id": "cell-a1781d52022d7358",
          "locked": true,
          "points": 1.25,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "2cf8e351"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ea902aa",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9d1492480edafa5422447da79b54502f",
          "grade": false,
          "grade_id": "cell-6b4d01a20202fb44",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9ea902aa"
      },
      "source": [
        "## Submitting your work\n",
        "\n",
        "**Important**: Please make sure that the submitted notebooks have been run and the cell outputs are visible.\n",
        "\n",
        "**Important**: Please make also sure that you have filled the **NAME** and **DNI** variables at the beginning of the notebook, **using the indicated format**.\n",
        "\n",
        "Once you have filled out the necessary code and you are happy with your solution, **save your notebook** and execute the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b13fea",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7d2689f958e6f950437e19eb4e061e63",
          "grade": false,
          "grade_id": "cell-40ddf258eb58940c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "97b13fea"
      },
      "outputs": [],
      "source": [
        "zip_filename = DNI + '_A3.zip'\n",
        "zf = zipfile.ZipFile(zip_filename, mode = 'w')\n",
        "\n",
        "aname = 'submitted/' + DNI + '/A3/Advanced_Techniques.ipynb'\n",
        "zf.write('Advanced_Techniques.ipynb', arcname = aname);\n",
        "\n",
        "zf.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07735c6c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "646263d4a3161e90f4369de935331304",
          "grade": false,
          "grade_id": "cell-8c14ebf9fa4805a7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "07735c6c"
      },
      "source": [
        "This will generate a zip file of your code called `DNI_A3.zip` in the same directory of the assignment. This is the file that you must upload to [Aula Digital](https://uibdigital.uib.es/) to submit your work!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7760aba2",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a3e5f552b4935747a0f94ab360623ea5",
          "grade": false,
          "grade_id": "cell_foot_1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7760aba2"
      },
      "source": [
        "---\n",
        "\n",
        "&copy; Emilio Garcia-Fidalgo, University of the Balearic Islands"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}