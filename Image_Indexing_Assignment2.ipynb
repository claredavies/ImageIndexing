{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claredavies/ImageIndexing/blob/master/Image_Indexing_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a795ccf4",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b361c569619c5777091368813c9298fb",
          "grade": false,
          "grade_id": "cell_head_1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "a795ccf4"
      },
      "source": [
        "# 11762 Content-Based Image Retrieval\n",
        "## Master's Degree in Intelligent Systems\n",
        "### University of the Balearic Islands\n",
        "\n",
        "---\n",
        "\n",
        "**Before you turn this problem in, please put your full names and DNIs (or NIEs) below, and execute the cell:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6947b975",
      "metadata": {
        "id": "6947b975"
      },
      "outputs": [],
      "source": [
        "NAME  = \"Clare Davies\"\n",
        "DNI   = \"99999999R\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/claredavies/ImageIndexing\n",
        "%cd ImageIndexing\n",
        "!git checkout master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1GKGNKFQ_JY",
        "outputId": "fc68e314-da25-47a9-b26f-443a4d3d2566"
      },
      "id": "Q1GKGNKFQ_JY",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ImageIndexing'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 110 (delta 19), reused 3 (delta 0), pack-reused 71\u001b[K\n",
            "Receiving objects: 100% (110/110), 141.66 MiB | 29.56 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n",
            "/content/ImageIndexing\n",
            "Branch 'master' set up to track remote branch 'master' from 'origin'.\n",
            "Switched to a new branch 'master'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec32c2c0",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6e99971bb70936fbf488fd64ed0c1efa",
          "grade": false,
          "grade_id": "cell_head_2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ec32c2c0"
      },
      "source": [
        "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. **Justify** all of your answers, **graphically** wherever possible. Remember that this notebook will be considered as a report to the work done during the assignment.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a32b507a",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4ed34114414f947ea18f0e3a656381d9",
          "grade": false,
          "grade_id": "cell-f6e621d3dd92a9f1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "a32b507a"
      },
      "outputs": [],
      "source": [
        "# Setup code for this assignment\n",
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import scipy.cluster.vq as vq\n",
        "import tqdm\n",
        "import zipfile\n",
        "\n",
        "## Adding parent folder to find other libs\n",
        "import sys\n",
        "if \"..\" not in sys.path:\n",
        "    sys.path.insert(0,\"..\")\n",
        "    \n",
        "import iric_dev_kit.iric_utils.eval_holidays as ev\n",
        "import iric_dev_kit.iric_utils.read_descriptors as rd\n",
        "\n",
        "# Configuring Matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d621778b",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "dbebddc8d595e79783bf0d05156e3b2e",
          "grade": false,
          "grade_id": "cell-3b814276a5ba86db",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d621778b"
      },
      "source": [
        "## Introduction\n",
        "In this assignment, you will implement and evaluate different methods for indexing images. As usual during this course, we will use the [INRIA Holidays](http://lear.inrialpes.fr/people/jegou/data.php) dataset. **Check the Assignment 1 to further information about this dataset.**\n",
        "\n",
        "We also need the provided script to evaluate a CBIR system on this dataset. Remember that the performance is measured computing the **mean average precision** (mAP) over all queries. **Check also the Assignment 1 to remember how to use this script and the different functions it offers.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77b3c399",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f525c9b743f3383ec8f06c742e58a752",
          "grade": false,
          "grade_id": "cell-da4850e64a976ad8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "77b3c399"
      },
      "source": [
        "### Loading images\n",
        "As we did in Assignment 1, for managing images, we will create four lists:\n",
        "- **`query_names`**: File names of the *query* images\n",
        "- **`query_imgs`**: *Query* images loaded using OpenCV2\n",
        "- **`train_names`**: File names of the *train* (database) images\n",
        "- **`train_imgs`**: *Train* images loaded using OpenCV2\n",
        "\n",
        "In this assignment, we will use the original holidays dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "78adf5f7",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "41c749ebe18a13ff129bf6ea5c39b005",
          "grade": false,
          "grade_id": "cell-a926eab7930fc8b4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78adf5f7",
        "outputId": "efba2416-af9c-4131-dc5f-a5c9a01cba9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "31\n"
          ]
        }
      ],
      "source": [
        "# Separating the dataset into query and train images\n",
        "query_names = []\n",
        "query_imgs = []\n",
        "train_names = []\n",
        "train_imgs = []\n",
        "\n",
        "# with open('../holidays/holidays_images.dat') as f:\n",
        "\n",
        "with open('holidays_mini/holidays_images.dat') as f:\n",
        "    for line in f:\n",
        "        imname = line.strip()\n",
        "        imno = int(imname[:-len(\".jpg\")])\n",
        "        # img = cv2.imread('../holidays/images/' + imname)\n",
        "\n",
        "        img = cv2.imread('holidays_mini/images/' + imname)\n",
        "        # Resize the images for a faster operation in this assignment\n",
        "        img = cv2.resize(img, None, fx=0.25, fy=0.25, interpolation = cv2.INTER_CUBIC)\n",
        "    \n",
        "        # Checking if this is a query image\n",
        "        if imno % 100 == 0:\n",
        "            query_names.append(imname)\n",
        "            query_imgs.append(img)\n",
        "        else:\n",
        "            train_names.append(imname)\n",
        "            train_imgs.append(img)\n",
        "\n",
        "print(len(query_names))\n",
        "print(len(train_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27d7080b",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3a11200089c6a5d774184687648c838a",
          "grade": false,
          "grade_id": "cell-e0f678da073b3399",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "27d7080b"
      },
      "source": [
        "## Loading SIFT descriptors\n",
        "In this assignment we will create four additional lists:\n",
        "- **`query_kps`**: A list of lists of keypoints (cv2.KeyPoint) extracted from the *query* images\n",
        "- **`query_desc`**: A list of numpy arrays including, for each set of keypoints, the SIFT descriptors extracted from the *query* images\n",
        "- **`train_kps`**: A list of lists of keypoints (cv2.KeyPoint) extracted from the *train* (database) images\n",
        "- **`train_desc`**: A list of numpy arrays including, for each set of keypoints, the SIFT descriptors extracted from the *train* images\n",
        "\n",
        "Unlike in Assigment 1, now you will be provided with a set of SIFT descriptors for each image, and, therefore, you do not need to create these lists from scratch. First, download the descriptors from [here](https://uibes-my.sharepoint.com/:u:/g/personal/egf350_id_uib_es/Eam8Ld8YDaJAhNr91YVdAZIB_wVZJ8kzzKD7BR6R3LziMw).\n",
        "\n",
        "> **Unzip this file into the root directory of the development kit, at the same level of the datasets.**\n",
        "\n",
        "Now, a new directory called `siftgeo` should be in your workspace, containing the set of SIFT descriptors for each image of the dataset. These descriptors are stored in binary format and, thus, you are also provided with some tools to load them. To be more precise, you can call the function `load_SIFT_descriptors` to load the descriptors of a list of images:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"siftgeo.tar.gz\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Ng2uW0I7n7oY",
        "outputId": "a780b322-0ae1-4ad6-b806-32a7f94b7776"
      },
      "id": "Ng2uW0I7n7oY",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bd8072288abb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"siftgeo.tar.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                 \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0o700\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m             \u001b[0;31m# Do not set_attrs directories, as we will do that further down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m             self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),\n\u001b[0m\u001b[1;32m   2046\u001b[0m                          numeric_owner=numeric_owner)\n\u001b[1;32m   2047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2086\u001b[0;31m             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n\u001b[0m\u001b[1;32m   2087\u001b[0m                                  \u001b[0mset_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2088\u001b[0m                                  numeric_owner=numeric_owner)\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mmakefile\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2206\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2208\u001b[0;31m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmakeunknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                 raise EOFError(\"Compressed file ended before the \"\n\u001b[0m\u001b[1;32m    507\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f7e7e1c5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cc1b6e828616c74eecb5bd75ed481bf1",
          "grade": false,
          "grade_id": "cell-b4d6c65646fac5e2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7e7e1c5",
        "outputId": "9fa7d43d-b71a-4f1a-ef4a-d395d1bc0246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n",
            "31\n",
            "19\n",
            "31\n",
            "(1000, 128)\n",
            "[[10.  6. 52. ... 15.  4.  0.]\n",
            " [16. 50. 12. ... 15.  4.  0.]\n",
            " [10. 11. 58. ...  7.  4.  4.]\n",
            " ...\n",
            " [27. 15.  0. ... 16.  8. 12.]\n",
            " [51. 47. 14. ... 35. 26.  0.]\n",
            " [ 2. 37. 25. ... 47. 13.  8.]]\n"
          ]
        }
      ],
      "source": [
        "# Loading descriptors\n",
        "query_kps, query_desc = rd.load_SIFT_descriptors(query_names, max_desc=1000)\n",
        "train_kps, train_desc = rd.load_SIFT_descriptors(train_names, max_desc=1000)\n",
        "\n",
        "# Some prints\n",
        "print(len(query_kps))\n",
        "print(len(train_kps))\n",
        "print(len(query_desc))\n",
        "print(len(train_desc))\n",
        "print(query_desc[0].shape)\n",
        "print(query_desc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b8f8d0c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "def82a2846a9805038575d7a32f876d1",
          "grade": false,
          "grade_id": "cell-ab2d437e9c4904da",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6b8f8d0c"
      },
      "source": [
        "For development purposes, we use the parameter `max_desc` to load a maximum number (1000) of the descriptors. This will speed up the execution of the rest of the notebook, while the decrease in performance will be minimum.\n",
        "\n",
        "> **Some images do not have keypoints/descriptors. Take this into account when you develop your solution.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e2aeee4",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "60adae6f4efbeab4f703dbd5766b886a",
          "grade": false,
          "grade_id": "cell-d1426301b6919ea6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9e2aeee4"
      },
      "source": [
        "## $k$-d trees and LSH \n",
        "Let's start coding. At this section, you will develop a retrieval system using $k$-d trees and Locality Sensitive Hashing (LSH). "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b5ec641",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f777b4f2f29da5a3b28c0c26ca4e9859",
          "grade": false,
          "grade_id": "cell-06801f1c07fb6919",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9b5ec641"
      },
      "source": [
        "### General framework\n",
        "As we did in the first assignment, you first will develop some utilities to simplify your work. Write a function called `search_image` to search an image in a generic index (database). You should search each descriptor of the given query image and obtain its two closest SIFT descriptors in the database. Next, the initial set of matches should be filtered using the **NNDR criterion (use 0.8 as ratio)**, as you did in the previous assignment. For each database image, its final score with regard to this query image will be the **number of correct matches** with this image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9560c34",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "83f21825a10b2eff1d2829d308a0fd11",
          "grade": false,
          "grade_id": "cell-0bdc1eecfec1c973",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "d9560c34"
      },
      "outputs": [],
      "source": [
        "def search_image(descs, index, id_to_name):\n",
        "    \"\"\"\n",
        "    Search an image in the index\n",
        "    \n",
        "    - descs: A numpy array. This is the set descriptors extracted from the query image\n",
        "    - index: OpenCV FLANN index to search for descriptors.\n",
        "    - id_to_name: An associative list to link every image index to its real name\n",
        "        e.g. id_to_name[0] = '100001.jpg', id_to_name[1] = '100002.jpg'\n",
        "  \n",
        "    RETURN: \n",
        "    - An ordered list of similar images, e.g.: ['100101.jpg', '100202.jpg', ...]\n",
        "    \"\"\"\n",
        "\n",
        "    # Query the index for the closest descriptors\n",
        "    _, indices = index.knnSearch(descs, k=2, params={})\n",
        "    \n",
        "    # Filter matches using NNDR criterion\n",
        "    threshold = 0.8\n",
        "    mask = np.where(_[:, 0] < threshold * _[:, 1])\n",
        "    indices = indices[mask][:, 0]\n",
        "    \n",
        "    # Count the number of matches for each image\n",
        "    counts = np.zeros(len(id_to_name), dtype=np.int32)\n",
        "    for index in indices:\n",
        "        counts[index] += 1\n",
        "        \n",
        "    # Sort images by number of matches\n",
        "    order = np.argsort(-counts)\n",
        "    result = [id_to_name[i] for i in order if counts[i] > 0]\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5470e6a8",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9645cb4e0f90d6437de5fa72c21ef651",
          "grade": false,
          "grade_id": "cell-349a4f0ebb8e378b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "5470e6a8"
      },
      "source": [
        "Now, write a function called `compute_mAP`. Given a list of query images and a trained index, this function should return a Python dictionary with the ordered results for each query along with the computed mAP:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNaBgdj6AYNJ",
        "outputId": "9a35b158-3faf-4853-b733-fd5f2f0ac235"
      },
      "id": "WNaBgdj6AYNJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['100000.jpg', '100100.jpg', '100200.jpg', '100300.jpg', '100400.jpg', '100500.jpg', '100600.jpg', '100700.jpg', '100800.jpg', '100900.jpg', '101000.jpg', '101100.jpg', '101200.jpg', '101300.jpg', '101400.jpg', '101500.jpg', '101600.jpg', '101700.jpg', '101800.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_desc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0ZbKLFRAbiI",
        "outputId": "b21224b1-802f-43ba-813e-b44572f2a8f7"
      },
      "id": "u0ZbKLFRAbiI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10.  6. 52. ... 15.  4.  0.]\n",
            " [16. 50. 12. ... 15.  4.  0.]\n",
            " [10. 11. 58. ...  7.  4.  4.]\n",
            " ...\n",
            " [27. 15.  0. ... 16.  8. 12.]\n",
            " [51. 47. 14. ... 35. 26.  0.]\n",
            " [ 2. 37. 25. ... 47. 13.  8.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "RxjRYZ6HAn7I",
        "outputId": "89305bd7-38c3-4f3c-8667-fb3a46d5c7c2"
      },
      "id": "RxjRYZ6HAn7I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-ec8a2109901f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0195c2f4",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5bc12399d04420171b09954818212fde",
          "grade": false,
          "grade_id": "cell-c3ba4bcd35106be8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "0195c2f4"
      },
      "outputs": [],
      "source": [
        "def compute_mAP(query_names, query_desc, index, id_to_name, gt_file):\n",
        "    \"\"\"\n",
        "    Perform a search for a list of query images against the database.\n",
        "    \n",
        "    - query_names: An ordered list with the names of the query images\n",
        "    - query_desc: A list containing numpy arrays of size (ndesc_for_this_image, 128)\n",
        "                  Each numpy array i corresponds to the descriptors found at image i\n",
        "    - index: FLANN index\n",
        "    - id_to_name: An associative array to link every image index to its real name\n",
        "                  e.g. id_to_name[0] = '100001.jpg', id_to_name[1] = '100002.jpg'\n",
        "  \n",
        "    RETURN: \n",
        "    - total_results: A dictionary containing, for each query image, an sorted list of the database images\n",
        "    - m_ap: Mean Average Precision averaged over all queries\n",
        "    \"\"\"\n",
        "    total_results = {}\n",
        "    m_ap = 0.0\n",
        "  \n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    #  # Initialize variables\n",
        "    # total_results = {}\n",
        "    # sum_ap = 0\n",
        "    # n_queries = len(query_names)\n",
        "    \n",
        "    # # Compute results for each query image\n",
        "    # for i in range(n_queries):\n",
        "    #     query_name = query_names[i]\n",
        "    #     query_descs = query_desc[i]\n",
        "        \n",
        "    #     # Perform the search\n",
        "    #     db_names = search_image(query_descs, index, id_to_name)\n",
        "    #     total_results[query_name] = db_names\n",
        "        \n",
        "    #     # Compute AP using the available function\n",
        "    #     ap = compute_AP(query_name, db_names, gt_file)\n",
        "    #     sum_ap += ap\n",
        "    \n",
        "    # # Compute mAP\n",
        "    # m_ap = sum_ap / n_queries\n",
        "    \n",
        "    return total_results, m_ap"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a7782f8",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3eda381e7ffcc78a7ec1e7c916eab2a2",
          "grade": false,
          "grade_id": "cell-41b189c4ea538e00",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6a7782f8"
      },
      "source": [
        "### $k$-d Trees\n",
        "In this section you will use a set of randomized $k$-d trees to index the database of images. Write a function called `build_db_kdtrees` to build a set of randomized $k$-d trees given a set of descriptors:\n",
        "\n",
        "> **Useful links**: [cv2.FlannBasedMatcher](https://docs.opencv.org/4.5.5/dc/de2/classcv_1_1FlannBasedMatcher.html), [Possible algorithms to create an index](https://docs.opencv.org/4.5.5/db/d18/classcv_1_1flann_1_1GenericIndex.html#a8fff14185f9f3d2f2311b528f65b146c), [Algorithms IDs](https://github.com/opencv/opencv/blob/master/modules/flann/include/opencv2/flann/defines.h#L70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3586111e",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7a4f13ccc15c7eb033518fc08fabcfff",
          "grade": false,
          "grade_id": "cell-19e04b97f8d87a86",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3586111e"
      },
      "outputs": [],
      "source": [
        "def build_db_kdtrees(descs, ntrees = 4):\n",
        "    \"\"\"\n",
        "    Build a set of randomized k-d trees.\n",
        "    \n",
        "    - descs: A list of length len(img_names) where each element is a numpy array \n",
        "        of size (ndesc_for_this_image, 128). Each numpy array i corresponds \n",
        "        to the descriptors found on image i\n",
        "    - ntrees: Number of trees to train\n",
        "  \n",
        "    RETURN: \n",
        "    - index: Trained FLANN index\n",
        "    \"\"\"  \n",
        "  \n",
        "     # Concatenate descriptors from all images\n",
        "    descriptors = np.concatenate(descs)\n",
        "    \n",
        "    # Define FLANN parameters\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=ntrees)\n",
        "    search_params = dict(checks=50)\n",
        "    \n",
        "    # Create FLANN index\n",
        "    index = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "    index.add(descriptors)\n",
        "    \n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fe39d9d",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eb2220563691ccf61e3d342d9b287da7",
          "grade": true,
          "grade_id": "cell-803ccdc307b881ec",
          "locked": true,
          "points": 0.35,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fe39d9d",
        "outputId": "deeee8d1-88f0-4313-e778-133117748661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1103\n"
          ]
        }
      ],
      "source": [
        "# Simple example of DB construction\n",
        "index = build_db_kdtrees(train_desc[0:2])\n",
        "print(len(index.getTrainDescriptors()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8598581a",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "78413f286a0c5bc8130c2fc5786a1872",
          "grade": true,
          "grade_id": "cell-207a3f0134254933",
          "locked": true,
          "points": 0.35,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8598581a"
      },
      "outputs": [],
      "source": [
        "# Search an image in the index\n",
        "img_res = search_image(query_desc[0], index, train_names[0:2])\n",
        "print(img_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c32c81c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9f8eea34eed5f81d059b93a46ecd69a8",
          "grade": true,
          "grade_id": "cell-bf632685cb412e33",
          "locked": true,
          "points": 0.25,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0c32c81c"
      },
      "outputs": [],
      "source": [
        "# Example of computing mAP\n",
        "results, mAP = compute_mAP(query_names, query_desc, index, train_names[0:2])\n",
        "print(results['100000.jpg'])\n",
        "print(results['100100.jpg'])\n",
        "print(mAP) # This should be 0 now, since there is only two images in the database."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec669537",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "88ad41437443c287f925e3cf262365ad",
          "grade": false,
          "grade_id": "cell-2ed91024e8f67fdf",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ec669537"
      },
      "source": [
        "**Q1**: Using functions developed so far, in the following cell compute the resulting **mAP** of the system **using 4 trees**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3d0cfe3",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "682488215de47970cc34d71265a92481",
          "grade": false,
          "grade_id": "cell-04f414377f3437e6",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "d3d0cfe3"
      },
      "outputs": [],
      "source": [
        "# Fill this variable with the resulting mAP\n",
        "mAP_kdtree = 0.0\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3ef5289",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b84112f2224a789def8dcb4f067f9314",
          "grade": true,
          "grade_id": "cell-26ff0e22e3398306",
          "locked": true,
          "points": 0.3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "f3ef5289"
      },
      "outputs": [],
      "source": [
        "print('mAP: %.5f' % mAP_kdtree)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57bae631",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8837b491f312c23d720b289d446df108",
          "grade": false,
          "grade_id": "cell-1beea12d1f8191d8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "57bae631"
      },
      "source": [
        "**Q2**: Are the results stable? Do you obtain always the same mAP? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72827768",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a083d74d09c0478de8347d42afc480e2",
          "grade": false,
          "grade_id": "cell-ec07385de7cc53f8",
          "locked": true,
          "points": 0.1,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "72827768"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8baed384",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c1c86d138c2c669b41e3a51679ce66bc",
          "grade": false,
          "grade_id": "cell-841e3c52c9507dd9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8baed384"
      },
      "source": [
        "**Q3:** Analyze the effect of changing the number of trees in terms of mAP and average response time. Some plots here can be useful to justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e57caf1",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5db66b397a32190212db1ae492721778",
          "grade": false,
          "grade_id": "cell-d936cbc9cbbff824",
          "locked": true,
          "points": 0.4,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "3e57caf1"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52633ad1",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8c4200b732e230d6a8a6b768558cdfd9",
          "grade": false,
          "grade_id": "cell-f1f7ebd50bedb10b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "52633ad1"
      },
      "source": [
        "### Locality Sensitive Hashing (LSH)\n",
        "In this section, you will use LSH to index the database of images. The LSH implementation included in OpenCV uses **bit sampling** for **Hamming distance** as a hash function and, therefore, binary descriptors must be used. Hence, SIFT descriptors are not valid and we need to describe the images, but using, for instance, ORB.\n",
        "\n",
        "In the following cell, write the code required to generate **roughly 1500 keypoints / descriptors** using ORB for each query / train image:\n",
        "\n",
        "> **Useful links**: [cv2.ORB_create](https://docs.opencv.org/4.5.4/db/d95/classcv_1_1ORB.html#aeff0cbe668659b7ca14bb85ff1c4073b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b1223cb",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "dc9a6073046a70410fc58fcb05637321",
          "grade": false,
          "grade_id": "cell-062e499099d47f25",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "4b1223cb"
      },
      "outputs": [],
      "source": [
        "query_kps_orb  = []\n",
        "query_desc_orb = []\n",
        "train_kps_orb  = []\n",
        "train_desc_orb = []\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03aa9edf",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f9a38f6232680ae68df6075ea3ebc06f",
          "grade": true,
          "grade_id": "cell-6d11da6cb5de46b2",
          "locked": true,
          "points": 0.25,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "03aa9edf"
      },
      "outputs": [],
      "source": [
        "# Show some data\n",
        "print(len(query_kps_orb[0]))\n",
        "print(query_desc_orb[0].shape)\n",
        "print(query_desc_orb[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3362cc8",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9a9880eb8c1c99547f3fe1539255e4d6",
          "grade": false,
          "grade_id": "cell-a600dc9ab1f5c001",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "b3362cc8"
      },
      "source": [
        "Next, write a function called `build_db_lsh` to build a **standard** (*no multi-probe*) LSH index from a set of images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f4e0e3e",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "01a750d8c65eeb552ecc7df3d46c5dc4",
          "grade": false,
          "grade_id": "cell-93ee6119edf6b51c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "7f4e0e3e"
      },
      "outputs": [],
      "source": [
        "def build_db_lsh(descs, tables = 6, hash_size = 12):\n",
        "    \"\"\"\n",
        "    Index a set of images using LSH.    \n",
        "    \n",
        "    - descs: A list containing numpy arrays of size (~1500, 32). Each numpy array\n",
        "        i corresponds to the ORB descriptors found at image i.\n",
        "    - tables: Number of hash tables to create.\n",
        "    - hash_size: Hash length in bits.\n",
        "  \n",
        "    RETURN: \n",
        "    - index: The trained LSH index.\n",
        "    \"\"\"  \n",
        "    index = None\n",
        "  \n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "  \n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ccfabe",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9fdc504017e8d06899e084c165d74520",
          "grade": true,
          "grade_id": "cell-4cd31f9613416c8c",
          "locked": true,
          "points": 0.25,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "80ccfabe"
      },
      "outputs": [],
      "source": [
        "# Simple example of DB construction\n",
        "index = build_db_lsh(train_desc_orb[0:2])\n",
        "print(len(index.getTrainDescriptors()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e544ed8d",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "38d285da40073176866dd77553724748",
          "grade": false,
          "grade_id": "cell-a1da1133b9232fd9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "e544ed8d"
      },
      "source": [
        "**Q4**: In the following cell compute the resulting **mAP** of the system **using 6 tables and a hash size of 12**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a0ebcfb",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2f3191083982b55431eff3415f61b7f1",
          "grade": false,
          "grade_id": "cell-f87580b24fd1f890",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "1a0ebcfb"
      },
      "outputs": [],
      "source": [
        "# Fill this variable with the resulting mAP\n",
        "mAP_lsh = 0.0\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9716be7",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1f17a5c7ff24433ee72fc57309464e1d",
          "grade": true,
          "grade_id": "cell-ec858b0d23c14805",
          "locked": true,
          "points": 0.3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "c9716be7"
      },
      "outputs": [],
      "source": [
        "print('mAP: %.5f' % mAP_lsh)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e599bd3",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "366c9df3aeae12173192aac1056ff733",
          "grade": false,
          "grade_id": "cell-d8075ffe941e29c7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1e599bd3"
      },
      "source": [
        "**Q5**: Are the results stable? Do you obtain always the same mAP? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71126dfa",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c85322c4a8c34cc55f2f7ad98540d84b",
          "grade": false,
          "grade_id": "cell-edcdac402707a587",
          "locked": true,
          "points": 0.1,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "71126dfa"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64381fca",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c7f9251c9c2fb58a5c8da91e18ff247f",
          "grade": false,
          "grade_id": "cell-cc45a7e11a9d7418",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "64381fca"
      },
      "source": [
        "**Q6**: Analyze the effect of changing the number of tables / hash size in terms of mAP and average response time. Some plots here can be useful to justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7978b7c4",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8c93526152466646fa030e2f834b3a1d",
          "grade": false,
          "grade_id": "cell-619d74db24e88fa1",
          "locked": true,
          "points": 0.4,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "7978b7c4"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74726440",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "782f69599ceab03a607af447630838a5",
          "grade": false,
          "grade_id": "cell-188915bcd830f95d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "74726440"
      },
      "source": [
        "**Q7:** Despite the different descriptors used, compare the performance of the randomized k-d trees and LSH approaches from different points of view (accuracy, training times, querying times, ...). Some plots can be useful here to justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf65981",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a5c50934954a56f23bc0f37e08b7966c",
          "grade": false,
          "grade_id": "cell-4b9be38f6bd33f20",
          "locked": true,
          "points": 0.4,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "3cf65981"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d89bb5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "14f9f77fddd83546aa0e96298ad3d679",
          "grade": false,
          "grade_id": "cell-6c6989014e168fd5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d5d89bb5"
      },
      "source": [
        "## Bag-of-Words\n",
        "In this section, you will implement the Bag-of-Words (BoW) model for image retrieval. Additionally, you will also implement the TF-IDF scoring scheme."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b174ede",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4c2f0c59d241e9516d31054c2c930590",
          "grade": false,
          "grade_id": "cell-7947a0a3afccdc15",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9b174ede"
      },
      "source": [
        "### Download visual dictionaries\n",
        "To use a BoW model, first we need a visual vocabulary. The authors of the INRIA Holidays dataset provide some visual vocabularies, trained using a clustering method (e.g. $k$-means) in a different dataset (Flickr60K).\n",
        "\n",
        "First, download these vocabularies from [here](https://uibes-my.sharepoint.com/:u:/g/personal/egf350_id_uib_es/EY1G011OvfJOnwqWQQzmHmgBkXhLHBaK00wdizsUT252dw).\n",
        "\n",
        "> **Unzip this file into the root directory of the development kit, at the same level of the datasets.**\n",
        "\n",
        "A folder named `clust` is now available in your workspace, containing visual vocabularies of 100, 200, 500, 1K, 2K, 5K, 10K, 20K, 50K, 100K and 200K visual words. Again, these are binary files, and therefore we provide you with functions to load and index them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e26fefdc",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "260872183e8d586227feb2e0dd63b319",
          "grade": false,
          "grade_id": "cell-99af7beaa1c3d539",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "e26fefdc"
      },
      "outputs": [],
      "source": [
        "voc = rd.load_visual_vocab(\"../clust/clust_flickr60_k200.fvecs\", ntrees=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97d05851",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ea4b06e011018dbe3d7bf80de465099f",
          "grade": false,
          "grade_id": "cell-80d1363425120021",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "97d05851"
      },
      "source": [
        "With this function, the corresponding vocabulary is read. Additionally, a FLANN index structure based on kd-trees is built and returned using the centroids. This is to allow a fast access when searching for the closest visual words in the vocabulary. More precisely, in this example, 4 trees are constructed using the vocabulary of 200 centroids. Now, given a query descriptor(s), you can use `match` or `knnMatch` methods as usual to search for the closest (approximate) visual word(s) in the vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ccb141",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7d2acd3a78267653f70223cc6c6148fe",
          "grade": false,
          "grade_id": "cell-fe94465177ae4be8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "95ccb141"
      },
      "source": [
        "### BoW and Inverted File\n",
        "Now, write a class called `BoW` to manage the indexing procedure. This class should make use, in addition to the visual vocabulary, an inverted file to compute similarity scores between images. Apart from the class constructor, write three methods: `build_db`, `search_image` and `compute_mAP`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "802ae103",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3705eff4ede554054ae49d94217c495c",
          "grade": false,
          "grade_id": "cell-aeb911c85fbfcee0",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "802ae103"
      },
      "outputs": [],
      "source": [
        "class BoW:\n",
        "    \"\"\"\n",
        "    Class to implement the BoW model + Inverted File.\n",
        "    \"\"\"\n",
        "  \n",
        "    def __init__(self, vocab_file):\n",
        "        \"\"\"\n",
        "        Class constructor. It loads the vocabulary and initializes other stuff\n",
        "        required for the CBIR system, such as the inverted file structure.\n",
        "        \"\"\"\n",
        "        self.vocab = rd.load_visual_vocab(vocab_file)\n",
        "        self.nwords = self.vocab.getTrainDescriptors()[0].shape[0]\n",
        "        self.train_names = []\n",
        "        self.inv_list = {word_id: {} for word_id in range(self.nwords)}\n",
        "\n",
        "    def build_db(self, img_names, img_descs):\n",
        "        \"\"\"\n",
        "        Build an index from a set of images. Essentially, for each image, you should\n",
        "        search its descriptors in the index in order to find the closest visual words\n",
        "        and fill the inverted file structure consequently.\n",
        "    \n",
        "        - img_names: An ordered list with the names of the train images\n",
        "        - img_descs: A list containing numpy arrays. Each numpy array i corresponds \n",
        "          to the descriptors found at image i\n",
        "        \"\"\"\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def search_image(self, descs):\n",
        "        \"\"\"\n",
        "        Search an image in the index.\n",
        "      \n",
        "        - descs: A numpy array. It is the set descriptors extracted from the query image.\n",
        "    \n",
        "        RETURN:\n",
        "        - An ordered list of similar images, e.g.: ['100101.jpg', '100202.jpg', ...]\n",
        "        \"\"\"\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        \n",
        "    def compute_mAP(self, query_names, query_descs):\n",
        "        \"\"\"\n",
        "        Perform a search for a list of query images against the database and evaluates\n",
        "        the performance of the system.\n",
        "        \n",
        "        - query_names: An ordered list with the names of query images\n",
        "        - query_descs: A list containing numpy arrays of size (ndesc_for_this_image, 128). \n",
        "              Each numpy array i corresponds to the descriptors found at image i.\n",
        "\n",
        "        RETURN:\n",
        "        - total_results: A dictionary containing, for each query image, an ordered list of the retrieved images.\n",
        "        - m_ap: Mean Average Precision averaged over all queries.\n",
        "        \"\"\"\n",
        "        total_results = {}\n",
        "        m_ap = 0.0\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        \n",
        "        return total_results, m_ap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd007f2",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8cdbbd209adde95163e67301a02db290",
          "grade": true,
          "grade_id": "cell-f6be571325c7ade3",
          "locked": true,
          "points": 0.3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "efd007f2"
      },
      "outputs": [],
      "source": [
        "# Example of use\n",
        "index = BoW('../clust/clust_flickr60_k200.fvecs')\n",
        "index.build_db(train_names[0:2], train_desc[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b12b2730",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "444e59917aacd3108acb0d640bf30462",
          "grade": true,
          "grade_id": "cell-df1c6aaa914fbec3",
          "locked": true,
          "points": 0.4,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "b12b2730"
      },
      "outputs": [],
      "source": [
        "res = index.search_image(query_desc[0])\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1661e449",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b31bdb24f4274ae7866295e1a76c17c1",
          "grade": true,
          "grade_id": "cell-3cab945e87903d31",
          "locked": true,
          "points": 0.3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1661e449"
      },
      "outputs": [],
      "source": [
        "results, mAP = index.compute_mAP(query_names, query_desc)\n",
        "print(results)\n",
        "print(mAP)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5046a9c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "763e74c102202322912c057bc8327544",
          "grade": false,
          "grade_id": "cell-fdf71f42f5f298ce",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "a5046a9c"
      },
      "source": [
        "**Q8**: In the following cell compute the resulting mAP of the system **using the vocabularies of 200, 2K, 20K and 200K visual words**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8901aab",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "70f60d56a1270671470b02ff879a740d",
          "grade": false,
          "grade_id": "cell-4176faf951e0cc65",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "c8901aab"
      },
      "outputs": [],
      "source": [
        "# Fill these variables with the resulting mAP\n",
        "mAP_200  = 0.0\n",
        "mAP_2K   = 0.0\n",
        "mAP_20K  = 0.0\n",
        "mAP_200K = 0.0\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c1ed565",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fcea21868d957c7425e74ae4a5032825",
          "grade": true,
          "grade_id": "cell-f4374afc6ecce161",
          "locked": true,
          "points": 0.3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9c1ed565"
      },
      "outputs": [],
      "source": [
        "print('mAP 200: %.5f' % mAP_200)\n",
        "print('mAP 2K: %.5f' % mAP_2K)\n",
        "print('mAP 20K: %.5f' % mAP_20K)\n",
        "print('mAP 200K: %.5f' % mAP_200K)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e818e7c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "07f57bc9d9bd78d99b403602f8a90e44",
          "grade": false,
          "grade_id": "cell-e5a519c51fa0069b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "5e818e7c"
      },
      "source": [
        "**Q9**: Compare the performances obtained on each case. Is a larger vocabulary size always better? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6015870",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "564ebe7c40dcffe1c50dfe735098e350",
          "grade": false,
          "grade_id": "cell-9429db3024616a16",
          "locked": true,
          "points": 0.2,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "f6015870"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b582757",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8b81f882f6c67715a70baf6a6e3e38d1",
          "grade": false,
          "grade_id": "cell-971d658462e12e6e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7b582757"
      },
      "source": [
        "**Q10**: Analyze the effect of the vocabulary size in terms of mAP and average response time (train and query times). Are these times constant for each vocabulary? Some plots here can be useful to justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7695e01",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "193e620c3bf540dd97e40ee42b830638",
          "grade": false,
          "grade_id": "cell-1e355e0c5cb28de0",
          "locked": true,
          "points": 0.1,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "a7695e01"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98f5416",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cb7b5be6b81db0380ab35f49a6552a21",
          "grade": false,
          "grade_id": "cell-219866d30da6310f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "b98f5416"
      },
      "source": [
        "**Q11**: Do the results obtained depend on the set of images used to generate the vocabulary? How can we improve the retrieval performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7345924",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4e5d90633e2fc5b72aa613279c228f6c",
          "grade": false,
          "grade_id": "cell-96569c702b5b7198",
          "locked": true,
          "points": 0.1,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "a7345924"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28efbead",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fe4a6d363c03ec519f228f1c2fcb8a22",
          "grade": false,
          "grade_id": "cell-4795f460941688a9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "28efbead"
      },
      "source": [
        "### TF-IDF\n",
        "As a final task of this assignment, let's implement the TF-IDF scoring scheme. Modify the `BoW` class you wrote before to include the TF-IDF weighting scheme:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "593cafcc",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7a5bbebd21d49ef285373e0436c7e36c",
          "grade": false,
          "grade_id": "cell-a65f0d83a4e6326d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "593cafcc"
      },
      "outputs": [],
      "source": [
        "class BoW_TFIDF:\n",
        "    \"\"\"\n",
        "    Class to implement the BoW model + Inverted File + TF-IDF Scoring scheme\n",
        "    \"\"\"\n",
        "  \n",
        "    def __init__(self, vocab_file):\n",
        "        \"\"\"\n",
        "        Class constructor. It loads the vocabulary and initializes other stuff\n",
        "        required for the CBIR system, such as the inverted file structure.\n",
        "        \"\"\"\n",
        "        self.vocab = rd.load_visual_vocab(vocab_file)\n",
        "        self.nwords = self.vocab.getTrainDescriptors()[0].shape[0]\n",
        "        self.train_names = []\n",
        "        self.inv_list = {word_id: {} for word_id in range(self.nwords)}        \n",
        "        self.tfidf = {}\n",
        "\n",
        "    def build_db(self, img_names, img_descs):\n",
        "        \"\"\"\n",
        "        Build an index from a set of images. Essentially, for each image, you should\n",
        "        search its descriptors in the index in order to find the closest visual words\n",
        "        and fill the inverted file structure consequently. Additionally, TF and IDF terms\n",
        "        should be computed here.\n",
        "    \n",
        "        - img_names: An ordered list with the names of the train images\n",
        "        - img_descs: A list containing numpy arrays. Each numpy array i corresponds \n",
        "          to the descriptors found at image i\n",
        "        \"\"\"\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def search_image(self, descs):\n",
        "        \"\"\"\n",
        "        Search an image in the index. Use the TF-IDF here when scoring the images.\n",
        "      \n",
        "        - descs: A numpy array. It is the set descriptors extracted from the query image.\n",
        "    \n",
        "        RETURN:\n",
        "        - An ordered list of similar images, e.g.: ['100101.jpg', '100202.jpg', ...]\n",
        "        \"\"\"\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        \n",
        "    def compute_mAP(self, query_names, query_descs):\n",
        "        \"\"\"\n",
        "        Perform a search for a list of query images against the database and evaluates\n",
        "        the performance of the system.\n",
        "        \n",
        "        - query_names: An ordered list with the names of query images\n",
        "        - query_descs: A list containing numpy arrays of size (ndesc_for_this_image, 128). \n",
        "              Each numpy array i corresponds to the descriptors found at image i.\n",
        "\n",
        "        RETURN:\n",
        "        - total_results: A dictionary containing, for each query image, an ordered list of the retrieved images.\n",
        "        - m_ap: Mean Average Precision averaged over all queries.\n",
        "        \"\"\"\n",
        "        total_results = {}\n",
        "        m_ap = 0.0\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        \n",
        "        return total_results, m_ap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b50bb6a4",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2a7f9e72db766bbb46a9351d79c32153",
          "grade": true,
          "grade_id": "cell-5852069de28f4013",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "b50bb6a4"
      },
      "outputs": [],
      "source": [
        "# Example of use\n",
        "index = BoW_TFIDF('../clust/clust_flickr60_k200.fvecs')\n",
        "index.build_db(train_names[0:2], train_desc[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de5068e",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0becf97cffc51eee9453ec7f73d0b7bf",
          "grade": true,
          "grade_id": "cell-96c066a07526d05c",
          "locked": true,
          "points": 0.45,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6de5068e"
      },
      "outputs": [],
      "source": [
        "res = index.search_image(query_desc[0])\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a554f0a8",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "82c28d6c0fdd0e7ad5f379588c605055",
          "grade": false,
          "grade_id": "cell-575949824f2de049",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "a554f0a8"
      },
      "source": [
        "**Q12**: In the following cell compute the resulting mAP of the system **using the vocabularies of 200, 2K, 20K and 200K visual words**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6307706a",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8c95346b797b2cca41bcecdc3662a524",
          "grade": false,
          "grade_id": "cell-0d04839ddb813322",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "6307706a"
      },
      "outputs": [],
      "source": [
        "# Fill these variables with the resulting mAP\n",
        "mAP_200  = 0.0\n",
        "mAP_2K   = 0.0\n",
        "mAP_20K  = 0.0\n",
        "mAP_200K = 0.0\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba4761f6",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6875afc6dfca2a616f133288c78f80b8",
          "grade": true,
          "grade_id": "cell-376a7cc3cc44f953",
          "locked": true,
          "points": 0.3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ba4761f6"
      },
      "outputs": [],
      "source": [
        "print('mAP 200: %.5f' % mAP_200)\n",
        "print('mAP 2K: %.5f' % mAP_2K)\n",
        "print('mAP 20K: %.5f' % mAP_20K)\n",
        "print('mAP 200K: %.5f' % mAP_200K)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aa3cf87",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "58e36b7d12f7a1862ee69a275c488e78",
          "grade": false,
          "grade_id": "cell-72b92aeae5e2af5e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1aa3cf87"
      },
      "source": [
        "**Q13:** Compare the performances obtained on each case. Is a larger vocabulary size always better? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65d6852c",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a3f86e368c5ab58b8438a3e3f04f4ecb",
          "grade": false,
          "grade_id": "cell-cb30e6754f8a5982",
          "locked": true,
          "points": 0.2,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "65d6852c"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "752ac143",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1323fe25eb88898f8692a84bce80fd7d",
          "grade": false,
          "grade_id": "cell-48a4fa20de0d9cb3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "752ac143"
      },
      "source": [
        "**Q14**: Analyze the effect of the vocabulary size in terms of mAP and average response time (train and query times). Are these times constant for each vocabulary? Some plots here can be useful to justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c07db06d",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "893995c02d8723df87a01fb6358c0444",
          "grade": false,
          "grade_id": "cell-2ee84889d64d2b77",
          "locked": true,
          "points": 0.1,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "c07db06d"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efc83c87",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "47620cd7566940588cc996e91d08d89a",
          "grade": false,
          "grade_id": "cell-732533d28be0d7f8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "efc83c87"
      },
      "source": [
        "**Q15**: Do the results obtained depend on the set of images used to generate the vocabulary? How can we improve the retrieval performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61429d22",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "579ffa1118fbc2f4afcf2e41cfed997e",
          "grade": false,
          "grade_id": "cell-d18ed77c92a81b75",
          "locked": true,
          "points": 0.1,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "61429d22"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6465cfb0",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "19391fa0b37d795714ed3302f0847a36",
          "grade": false,
          "grade_id": "cell-e611dd64897c293c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6465cfb0"
      },
      "source": [
        "**Q16:** How does TF-IDF affect the performance? Better or worse? Does this make sense?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b193d85",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ee1bf086bcde24459725d8df028eed97",
          "grade": false,
          "grade_id": "cell-00341a8c321999b8",
          "locked": true,
          "points": 0.2,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "4b193d85"
      },
      "source": [
        "Write here the code required to answer the questions stated above. You can add more cells (code / markdown) at this point if you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b3b83bc",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6874518beeb5a091fed8581c10ef1011",
          "grade": false,
          "grade_id": "cell-6177cc11a553139d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8b3b83bc"
      },
      "source": [
        "## Submitting your work\n",
        "\n",
        "**Important**: Please make sure that the submitted notebooks have been run and the cell outputs are visible.\n",
        "\n",
        "**Important**: Please make also sure that you have filled the **NAME** and **DNI** variables at the beginning of the notebook, **using the indicated format**.\n",
        "\n",
        "Once you have filled out the necessary code and you are happy with your solution, **save your notebook** and execute the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ef0d318",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2fb2e4ea279e65bae1d2158cee2833cf",
          "grade": false,
          "grade_id": "cell-10bc3c3e005d0af2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0ef0d318"
      },
      "outputs": [],
      "source": [
        "zip_filename = DNI + '_A2.zip'\n",
        "zf = zipfile.ZipFile(zip_filename, mode = 'w')\n",
        "\n",
        "aname = 'submitted/' + DNI + '/A2/Image_Indexing.ipynb'\n",
        "zf.write('Image_Indexing.ipynb', arcname = aname);\n",
        "\n",
        "zf.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f06aa9d3",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a815169d0f7636892c4f183d383836a8",
          "grade": false,
          "grade_id": "cell-74b609759ffc12db",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "f06aa9d3"
      },
      "source": [
        "This will generate a zip file of your code called `DNI_A2.zip` in the same directory of the assignment. This is the file that you must upload to [Aula Digital](https://uibdigital.uib.es/) to submit your work!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55cb8ca9",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a3e5f552b4935747a0f94ab360623ea5",
          "grade": false,
          "grade_id": "cell_foot_1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "55cb8ca9"
      },
      "source": [
        "---\n",
        "\n",
        "&copy; Emilio Garcia-Fidalgo, University of the Balearic Islands"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}